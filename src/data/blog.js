// blog.js
export default [
  {
    title: "Building a Merchant Service Provider Platform with C#.NET and TeamCity",
    date: "August 15, 2025",
    excerpt: "I led the integration of new features and critical bug fixes on a major MSP platform. This post details how I configured TeamCity for CI/CD, drastically reducing deployment errors and accelerating the delivery pipeline.",
    content: `
<p>Working on the Merchant Service Provider project was a transformative experience. I led the integration of new features and performed critical bug fixes, ensuring seamless project delivery and enhanced functionality using the <strong>C#.NET</strong> framework.</p>

<h3>Automated CI/CD with TeamCity</h3>
<p>One of the key challenges was automating deployments for multiple .NET projects. I achieved this by configuring <strong>TeamCity</strong> for continuous integration and deployment (<strong>CI/CD</strong>), which provided several benefits:</p>
<ul>
    <li><strong>Reduced Errors:</strong> Minimized manual errors inherent in traditional deployment processes.</li>
    <li><strong>Accelerated Delivery:</strong> Streamlined the build and release pipeline, speeding up delivery by <strong>30%</strong>.</li>
    <li><strong>Robust Practices:</strong> Established a foundation for mature, reliable software delivery.</li>
</ul>
<p>The project taught me the critical importance of robust CI/CD practices in modern software development.</p>
    `.trim()
  },
  {
    title: "Centralized Data Syncing: Improving Factory Management with C#.NET",
    date: "July 30, 2025",
    excerpt: "I implemented a centralized C#.NET service to aggregate data from various factory locations into a central server, enabling real-time reporting and streamlining complex data management.",
    content: `
<p>Data management across multiple manufacturing facilities is inherently complex and prone to discrepancies. To tackle this, I designed and implemented a centralized syncing service in <strong>C#.NET</strong>.</p>

<h3>Key System Features</h3>
<p>This system aggregated operational data from disparate factory locations into a single, reliable central server. Its core achievements include:</p>
<ol>
    <li><strong>Real-Time Reporting:</strong> Enabled stakeholders to access current, accurate data instantly.</li>
    <li><strong>Data Integrity:</strong> Implemented efficient protocols to ensure accuracy and consistency during synchronization.</li>
    <li><strong>Simplified Operations:</strong> Streamlined complex data management tasks across the enterprise.</li>
</ol>
<p>This solution demonstrated how targeted technology can simplify large-scale operations and drive better, faster decision-making.</p>
    `.trim()
  },
  {
    title: "Developing an AI Chat-bot in Golang for Enhanced User Support",
    date: "July 10, 2025",
    excerpt: "I developed an AI-based chat-bot using Golang to provide instant assistance. This project highlights combining AI and NLP with Golang's concurrency for a fast, reliable, and scalable support system.",
    content: `
<p>Enhancing user support was the primary goal. I developed an <strong>AI-based chat-bot</strong> using <strong>Golang</strong> to provide instant assistance, significantly improving the overall user experience.</p>

<h3>Leveraging Golang's Performance</h3>
<p>The implementation focused on leveraging modern technologies for scalability:</p>
<ul>
    <li><strong>Natural Language Processing (NLP):</strong> Used to accurately interpret and respond to user queries.</li>
    <li><strong>Golang Concurrency:</strong> Exploited for high performance, resulting in a fast and reliable system.</li>
    <li><strong>Scalability:</strong> The architecture was designed to handle a growing volume of user interactions effortlessly.</li>
</ul>
<p>This project successfully integrated advanced AI with Golang's efficient backend capabilities to create an intelligent and scalable customer service solution.</p>
    `.trim()
  },
  {
    title: "AI-Powered Blank Field Detection in PDF Forms (Computer Vision)",
    date: "July 01, 2025",
    excerpt: "I created an AI system to automatically identify and extract blank fields in PDF forms, drastically improving data accuracy and processing efficiency for clients.",
    content: `
<p>Manual processing of PDF forms is notoriously slow and error-prone. To solve this, I engineered an <strong>AI-based system</strong> utilizing <strong>Computer Vision</strong> to automatically identify and extract data from blank fields within PDF documents.</p>

<h3>Impact on Business Value</h3>
<p>The innovation delivered critical improvements for clients:</p>
<ul>
    <li><strong>Data Accuracy:</strong> Significantly increased the reliability of extracted data.</li>
    <li><strong>Processing Efficiency:</strong> Drastically accelerated the form processing workflow.</li>
    <li><strong>Automation:</strong> Automated a previously tedious, manual, and high-volume task.</li>
</ul>
<p>This project showcased practical machine learning where specialized models were trained to recognize complex form structures, delivering <strong>tangible business value</strong> through automation.</p>
    `.trim()
  },
  {
    title: "Migrating Microservices from Delphi to Golang for Doc eSign",
    date: "June 20, 2025",
    excerpt: "I executed the conversion of core backend microservices from legacy Delphi to Golang, which significantly improved performance, scalability, and long-term maintainability for the Doc eSign platform.",
    content: `
<p>Legacy systems, in this case based on <strong>Delphi</strong>, often become bottlenecks for modern scalability and performance. For the Doc eSign project, I successfully executed the conversion of core backend microservices to <strong>Golang</strong>.</p>

<h3>Strategic Technical Benefits</h3>
<p>The strategic migration yielded several benefits:</p>
<ul>
    <li><strong>Improved Performance:</strong> Leveraged Golang's speed and concurrency for faster response times.</li>
    <li><strong>Enhanced Scalability:</strong> Provided a modern, robust architecture capable of handling future growth.</li>
    <li><strong>Long-Term Maintainability:</strong> Simplified the codebase and updated the technology stack.</li>
</ul>
<p>This experience reinforced the necessity of continuous modernization and selecting the appropriate technology stack for sustained success.</p>
    `.trim()
  },
  {
    title: "Deep Learning for Emotion Prediction Using Face Images",
    date: "June 25, 2025",
    excerpt: "Developed a deep learning model for real-time emotion prediction from facial images, achieving 66% accuracy on FER-2023 and OAHEGA-ERD datasets.",
    content: `
<p>Emotion prediction from facial images is a challenging application of <strong>Deep Learning</strong> and <strong>Computer Vision</strong>. I developed a model for real-time emotion prediction using the <strong>FER-2023</strong> and <strong>OAHEGA-ERD</strong> datasets.</p>

<h3>Project Focus Areas</h3>
<p>Key steps in the development process included:</p>
<ul>
    <li><strong>Data Preprocessing:</strong> Rigorously cleaned and prepared the large image datasets.</li>
    <li><strong>Model Selection:</strong> Chosen for balancing accuracy with computational efficiency.</li>
    <li><strong>Hyperparameter Tuning:</strong> Optimized the model to achieve a promising <strong>66% accuracy</strong>.</li>
</ul>
<p>This project provided deep insight into the complexities of computer vision, particularly in interpreting subtle human behavioral data using advanced AI techniques.</p>
    `.trim()
  },
  {
    title: "Sentiment Analysis with Coyote Optimization on Twitter Data",
    date: "June 10, 2025",
    excerpt: "Implemented Sentiment Analysis using the Coyote Optimization Algorithm on COVID-19 Twitter data, showcasing skills in applying advanced optimization techniques to NLP challenges.",
    content: `
<p>Social media provides a vast, noisy data source perfect for large-scale <strong>Sentiment Analysis</strong>. I executed a project utilizing the <strong>Coyote Optimization Algorithm (COA)</strong> to analyze public sentiment regarding COVID-19 from <strong>Twitter data</strong>.</p>

<h3>Methodology and Results</h3>
<p>The methodology was multi-faceted, combining several advanced techniques:</p>
<ol>
    <li><strong>Data Acquisition:</strong> Collected tweets efficiently via the Twitter API.</li>
    <li><strong>Text Preprocessing:</strong> Performed normalization and tokenization on the unstructured text.</li>
    <li><strong>Algorithm Application:</strong> Applied the COA to significantly improve classification accuracy compared to baseline models.</li>
</ol>
<p>This work effectively combined <strong>Data Science</strong>, optimization, and real-world analytics, demonstrating skill in extracting meaningful, quantifiable insights from large, unstructured datasets.</p>
    `.trim()
  },
];